{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#http://datareview.info/article/sovremennyie-metodyi-analiza-tonalnosti-teksta/\n",
    "import pandas\n",
    "import numpy as np\n",
    "positive_raw = pandas.read_csv('positive.csv', sep=';', header=None)\n",
    "negative_raw = pandas.read_csv('negative.csv', sep=';', header=None)\n",
    "print(type(positive_raw[[3,4]]))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_raw = positive_raw.append(negative_raw)\n",
    "all_raw = all_raw[[3, 4]]\n",
    "all_raw.columns = ['text', 'isPositive']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymorphy2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-24b35e09b031>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpymorphy2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmorph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpymorphy2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMorphAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_normalized_form\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmorph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal_form\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymorphy2'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "def get_normalized_form(word):\n",
    "    return morph.parse(word)[0].normal_form\n",
    "\n",
    "regex = re.compile(r\"@[\\w]+\")\n",
    "def proceed_string(input_str):\n",
    "    input_str = input_str.replace('\\n', ' ')\n",
    "    input_str = input_str.replace('\\\\n', ' ')\n",
    "    input_str = re.sub(r\"@[\\w]+:\", \"\", input_str)\n",
    "    input_str = re.sub(r\"[^ЁёА-Яа-я\\s]\", \" \", input_str)\n",
    "    input_str = input_str.lower()\n",
    "    words_arr = input_str.split()\n",
    "    words_arr = [get_normalized_form(w) for w in words_arr]\n",
    "    return words_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5288d1f2af1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproceed_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'all_raw' is not defined"
     ]
    }
   ],
   "source": [
    "all_raw['text'] = all_raw['text'].map(proceed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_raw['text'], all_raw['isPositive'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7289988, 9987315)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dim = 200\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "twits_w2v = Word2Vec(size=n_dim, min_count=5)\n",
    "twits_w2v.build_vocab(x_train)\n",
    "twits_w2v.train(x_train, total_examples=len(x_train), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_arr_to_vec(arr, length):\n",
    "    vec = np.zeros(length)\n",
    "    count = 0\n",
    "    for word in arr:\n",
    "        try:\n",
    "            vec += twits_w2v[word]\n",
    "            count += 1.0\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "train_vecs = np.array([word_arr_to_vec(arr, 200) for arr in x_train])\n",
    "train_vecs = scale(train_vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.42992090e-01, -1.25467266e+00,  4.29186582e-01, ...,\n",
       "        -4.56731803e-01,  1.18987826e+00, -9.12156055e-01],\n",
       "       [-1.81874605e-01, -6.73705269e-01,  8.95897185e-01, ...,\n",
       "         8.54989827e-01,  4.08406610e-01,  8.13921492e-02],\n",
       "       [ 1.59217758e+00,  9.69355688e-01,  4.17481647e-01, ...,\n",
       "         7.44258599e-01, -4.48830863e-01,  6.74723104e-01],\n",
       "       ...,\n",
       "       [-4.65848808e-01, -1.92089091e-01,  8.14199162e-01, ...,\n",
       "        -1.60599244e+00, -2.81689834e-01, -3.80773276e-01],\n",
       "       [ 5.34540833e-01, -9.00238657e-01,  9.92915665e-05, ...,\n",
       "         6.41597905e-01, -1.20730544e-01, -3.41209666e-01],\n",
       "       [ 9.31829394e-01,  1.33014805e-01,  5.56071351e-01, ...,\n",
       "        -5.09435601e-01, -1.36153644e+00,  2.23834933e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twits_w2v.train(x_test, total_examples=len(x_test), epochs=5)\n",
    "test_vecs = np.array([word_arr_to_vec(arr, 200) for arr in x_test])\n",
    "test_vecs = scale(test_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr = SGDClassifier(loss='log', penalty='l1')\n",
    "lr.fit(train_vecs, y_train)\n",
    "\n",
    "print ('Test Accuracy: %.2f'%lr.score(test_vecs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('страшный', 0.7219053506851196),\n",
       " ('странный', 0.7196283340454102),\n",
       " ('хороший', 0.6710162162780762),\n",
       " ('важный', 0.6643310785293579),\n",
       " ('ужасный', 0.6614466905593872),\n",
       " ('смешной', 0.6472550630569458),\n",
       " ('портить', 0.6304638981819153),\n",
       " ('умный', 0.6263653039932251),\n",
       " ('скучный', 0.6254901885986328),\n",
       " ('обычный', 0.622004508972168)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twits_w2v.most_similar(positive = 'плохой')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "diplom",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
